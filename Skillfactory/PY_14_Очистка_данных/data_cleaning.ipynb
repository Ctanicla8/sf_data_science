{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Читаем файл с данными:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>sub_area</th>\n",
       "      <th>preschool_quota</th>\n",
       "      <th>preschool_education_centers_raion</th>\n",
       "      <th>school_quota</th>\n",
       "      <th>school_education_centers_raion</th>\n",
       "      <th>school_education_centers_top_20_raion</th>\n",
       "      <th>...</th>\n",
       "      <th>office_km</th>\n",
       "      <th>additional_education_km</th>\n",
       "      <th>preschool_km</th>\n",
       "      <th>big_church_km</th>\n",
       "      <th>church_synagogue_km</th>\n",
       "      <th>theater_km</th>\n",
       "      <th>museum_km</th>\n",
       "      <th>ecology</th>\n",
       "      <th>mosque_count_1000</th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Bibirevo</td>\n",
       "      <td>5001.0</td>\n",
       "      <td>5</td>\n",
       "      <td>11065.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637189</td>\n",
       "      <td>0.947962</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>0.625783</td>\n",
       "      <td>0.628187</td>\n",
       "      <td>14.053047</td>\n",
       "      <td>7.389498</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>5850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Nagatinskij Zaton</td>\n",
       "      <td>3119.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6237.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688796</td>\n",
       "      <td>1.072315</td>\n",
       "      <td>0.273345</td>\n",
       "      <td>0.967821</td>\n",
       "      <td>0.471447</td>\n",
       "      <td>6.829889</td>\n",
       "      <td>0.709260</td>\n",
       "      <td>excellent</td>\n",
       "      <td>0</td>\n",
       "      <td>6000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Tekstil'shhiki</td>\n",
       "      <td>1463.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5580.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.543049</td>\n",
       "      <td>0.391957</td>\n",
       "      <td>0.158072</td>\n",
       "      <td>3.178751</td>\n",
       "      <td>0.755946</td>\n",
       "      <td>4.273200</td>\n",
       "      <td>3.156423</td>\n",
       "      <td>poor</td>\n",
       "      <td>0</td>\n",
       "      <td>5700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Mitino</td>\n",
       "      <td>6839.0</td>\n",
       "      <td>9</td>\n",
       "      <td>17063.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934273</td>\n",
       "      <td>0.892674</td>\n",
       "      <td>0.236455</td>\n",
       "      <td>1.031777</td>\n",
       "      <td>1.561505</td>\n",
       "      <td>16.990677</td>\n",
       "      <td>16.041521</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>13100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>77</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Basmannoe</td>\n",
       "      <td>3240.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7770.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077901</td>\n",
       "      <td>0.810801</td>\n",
       "      <td>0.376838</td>\n",
       "      <td>0.378756</td>\n",
       "      <td>0.121681</td>\n",
       "      <td>1.112486</td>\n",
       "      <td>1.800125</td>\n",
       "      <td>excellent</td>\n",
       "      <td>0</td>\n",
       "      <td>16331452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  full_sq  life_sq  floor           sub_area  preschool_quota  \\\n",
       "0   1       43     27.0    4.0           Bibirevo           5001.0   \n",
       "1   2       34     19.0    3.0  Nagatinskij Zaton           3119.0   \n",
       "2   3       43     29.0    2.0     Tekstil'shhiki           1463.0   \n",
       "3   4       89     50.0    9.0             Mitino           6839.0   \n",
       "4   5       77     77.0    4.0          Basmannoe           3240.0   \n",
       "\n",
       "   preschool_education_centers_raion  school_quota  \\\n",
       "0                                  5       11065.0   \n",
       "1                                  5        6237.0   \n",
       "2                                  4        5580.0   \n",
       "3                                  9       17063.0   \n",
       "4                                  7        7770.0   \n",
       "\n",
       "   school_education_centers_raion  school_education_centers_top_20_raion  ...  \\\n",
       "0                               5                                      0  ...   \n",
       "1                               8                                      0  ...   \n",
       "2                               7                                      0  ...   \n",
       "3                              10                                      0  ...   \n",
       "4                               9                                      0  ...   \n",
       "\n",
       "   office_km  additional_education_km  preschool_km  big_church_km  \\\n",
       "0   0.637189                 0.947962      0.177975       0.625783   \n",
       "1   0.688796                 1.072315      0.273345       0.967821   \n",
       "2   1.543049                 0.391957      0.158072       3.178751   \n",
       "3   0.934273                 0.892674      0.236455       1.031777   \n",
       "4   0.077901                 0.810801      0.376838       0.378756   \n",
       "\n",
       "   church_synagogue_km  theater_km  museum_km    ecology mosque_count_1000  \\\n",
       "0             0.628187   14.053047   7.389498       good                 0   \n",
       "1             0.471447    6.829889   0.709260  excellent                 0   \n",
       "2             0.755946    4.273200   3.156423       poor                 0   \n",
       "3             1.561505   16.990677  16.041521       good                 0   \n",
       "4             0.121681    1.112486   1.800125  excellent                 0   \n",
       "\n",
       "  price_doc  \n",
       "0   5850000  \n",
       "1   6000000  \n",
       "2   5700000  \n",
       "3  13100000  \n",
       "4  16331452  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sber_data = pd.read_csv('data/sber_data.csv')\n",
    "sber_df = sber_data.copy()\n",
    "sber_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sber_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sber_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sber_df.nunique()['sub_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sber_df.max()['price_doc']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке pandas реализован метод isnull(). Этот метод возвращает новый DataFrame, в ячейках которого стоят булевы значения True и False. True ставится на месте, где ранее находилось значение NaN.\n",
    "\n",
    "Посмотрим на результат работы метода на нашей таблице:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sber_data.isnull().tail())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для этого вычислим средний по столбцам результат метода isnull(). Получим долю пропусков в каждом столбце.\n",
    "\n",
    "Умножаем на 100 %, находим столбцы, где доля пропусков больше 0, сортируем по убыванию и выводим результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_null_percent = sber_data.isnull().mean() * 100\n",
    "cols_with_null = cols_null_percent[cols_null_percent>0].sort_values(ascending=False)\n",
    "display(cols_with_null)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно воспользоваться столбчатой диаграммой, чтобы визуально оценить соотношение числа пропусков к числу записей. Самый быстрый способ построить её — использовать метод plot():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_null.plot(\n",
    "    kind='bar',\n",
    "    figsize=(10, 4),\n",
    "    title='Распределение пропусков в данных'\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё один распространённый способ визуализации пропусков — тепловая карта. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'yellow'] \n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "cols = cols_with_null.index\n",
    "ax = sns.heatmap(\n",
    "    sber_data[cols].isnull(),\n",
    "    cmap=sns.color_palette(colors),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предварительно создадим копию исходной таблицы — drop_data, чтобы не повредить её. Зададимся порогом в 70 %: будем оставлять только те столбцы, в которых 70 и более процентов записей не являются пустыми . После этого удалим записи, в которых содержится хотя бы один пропуск. Наконец, выведем информацию о числе пропусков и наслаждаемся нулями. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаем копию исходной таблицы\n",
    "drop_data = sber_data.copy()\n",
    "#задаем минимальный порог: вычисляем 70% от числа строк\n",
    "thresh = drop_data.shape[0]*0.7\n",
    "#удаляем столбцы, в которых более 30% (100-70) пропусков\n",
    "drop_data = drop_data.dropna(thresh=thresh, axis=1)\n",
    "#удаляем записи, в которых есть хотя бы 1 пропуск\n",
    "drop_data = drop_data.dropna(how='any', axis=0)\n",
    "#отображаем результирующую долю пропусков\n",
    "drop_data.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(drop_data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполнение значений осуществляется с помощью метода fillna(). Главный параметр метода — value (значение, на которое происходит заполнение данных в столбце). Если метод вызывается от имени всего DataFrame, то в качестве value можно использовать словарь, где ключи — названия столбцов таблицы, а значения словаря — заполняющие константы. \n",
    "\n",
    "Создадим такой словарь, соблюдая рекомендации, приведённые выше, а также копию исходной таблицы. Произведём операцию заполнения с помощью метода fillna() и удостоверимся, что пропусков в данных больше нет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаем копию исходной таблицы\n",
    "fill_data = sber_data.copy()\n",
    "#создаем словарь имя столбца: число(признак) на который надо заменить пропуски\n",
    "values = {\n",
    "    'life_sq': fill_data['full_sq'],\n",
    "    'metro_min_walk': fill_data['metro_min_walk'].median(),\n",
    "    'metro_km_walk': fill_data['metro_km_walk'].median(),\n",
    "    'railroad_station_walk_km': fill_data['railroad_station_walk_km'].median(),\n",
    "    'railroad_station_walk_min': fill_data['railroad_station_walk_min'].median(),\n",
    "    'hospital_beds_raion': fill_data['hospital_beds_raion'].mode()[0],\n",
    "    'preschool_quota': fill_data['preschool_quota'].mode()[0],\n",
    "    'school_quota': fill_data['school_quota'].mode()[0],\n",
    "    'floor': fill_data['floor'].mode()[0]\n",
    "}\n",
    "#заполняем пропуски в соответствии с заявленным словарем\n",
    "fill_data = fill_data.fillna(values)\n",
    "#выводим результирующую долю пропусков\n",
    "fill_data.isnull().mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполнение недостающих значений константами с добавлением индикатора"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на реализацию. Как обычно, создадим копию indicator_data исходной таблицы. В цикле пройдёмся по столбцам с пропусками и будем добавлять в таблицу новый признак (с припиской \"was_null\"), который получается из исходного с помощью применения метода isnull(). После чего произведём обычное заполнение пропусков, которое мы совершали ранее, и выведем на экран число отсутствующих значений в столбце, чтобы убедиться в результате:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаем копию исходной таблицы\n",
    "indicator_data = sber_data.copy()\n",
    "#в цикле пробегаемся по названиям столбцов с пропусками\n",
    "for col in cols_with_null.index:\n",
    "    #создаем новый признак-индикатор как col_was_null\n",
    "    indicator_data[col + '_was_null'] = indicator_data[col].isnull()\n",
    "#создаем словарь имя столбца: число(признак) на который надо заменить пропуски   \n",
    "values = {\n",
    "    'life_sq': indicator_data['full_sq'],\n",
    "    'metro_min_walk': indicator_data['metro_min_walk'].median(),\n",
    "    'metro_km_walk': indicator_data['metro_km_walk'].median(),\n",
    "    'railroad_station_walk_km': indicator_data['railroad_station_walk_km'].median(),\n",
    "    'railroad_station_walk_min': indicator_data['railroad_station_walk_min'].median(),\n",
    "    'hospital_beds_raion': indicator_data['hospital_beds_raion'].mode()[0],\n",
    "    'preschool_quota': indicator_data['preschool_quota'].mode()[0],\n",
    "    'school_quota': indicator_data['school_quota'].mode()[0],\n",
    "    'floor': indicator_data['floor'].mode()[0]\n",
    "}\n",
    "#заполняем пропуски в соответствии с заявленным словарем\n",
    "indicator_data = indicator_data.fillna(values)\n",
    "#выводим результирующую долю пропусков\n",
    "indicator_data.isnull().mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Комбинирование методов\n",
    "\n",
    "Наверняка вы уже догадались, что необязательно использовать один метод. Вы можете их комбинировать. Например, мы можем:\n",
    "\n",
    "    удалить столбцы, в которых более 30 % пропусков;\n",
    "    удалить записи, в которых более двух пропусков одновременно;\n",
    "    заполнить оставшиеся ячейки константами.\n",
    "\n",
    "Посмотрим на реализацию такого подхода в коде:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаём копию исходной таблицы\n",
    "combine_data = sber_data.copy()\n",
    "\n",
    "#отбрасываем столбцы с числом пропусков более 30% (100-70)\n",
    "n = combine_data.shape[0] #число строк в таблице\n",
    "thresh = n*0.7\n",
    "combine_data = combine_data.dropna(thresh=thresh, axis=1)\n",
    "\n",
    "#отбрасываем строки с числом пропусков более 2 в строке\n",
    "m = combine_data.shape[1] #число признаков после удаления столбцов\n",
    "combine_data = combine_data.dropna(thresh=m-2, axis=0)\n",
    "\n",
    "#создаём словарь 'имя_столбца': число (признак), на который надо заменить пропуски \n",
    "values = {\n",
    "    'life_sq': combine_data['full_sq'],\n",
    "    'metro_min_walk': combine_data['metro_min_walk'].median(),\n",
    "    'metro_km_walk': combine_data['metro_km_walk'].median(),\n",
    "    'railroad_station_walk_km': combine_data['railroad_station_walk_km'].median(),\n",
    "    'railroad_station_walk_min': combine_data['railroad_station_walk_min'].median(),\n",
    "    'preschool_quota': combine_data['preschool_quota'].mode()[0],\n",
    "    'school_quota': combine_data['school_quota'].mode()[0],\n",
    "    'floor': combine_data['floor'].mode()[0]\n",
    "}\n",
    "#заполняем оставшиеся записи константами в соответствии со словарем values\n",
    "combine_data = combine_data.fillna(values)\n",
    "#выводим результирующую долю пропусков\n",
    "display(combine_data.isnull().mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть у нас есть признак, по которому мы будем искать выбросы. Давайте рассчитаем его статистические показатели (минимум, максимум, среднее, квантили) и по ним попробуем определить наличие аномалий.\n",
    "\n",
    "Сделать это можно с помощью уже знакомого вам метода describe(). Рассчитаем статистические показатели для признака жилой площади (life_sq)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sber_data['life_sq'].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что нам говорит метод describe()? Во-первых, у нас есть квартиры с нулевой жилой площадью. Во-вторых, в то время как 75-й квантиль равен 43, максимум превышает 7 тысяч квадратных метров (целый дворец, а не квартира!). \n",
    "\n",
    "Найдём число квартир с нулевой жилой площадью:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sber_data[sber_data['life_sq'] == 0].shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь выведем здания с жилой площадью более 7 000 квадратных метров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sber_data[sber_data['life_sq'] > 7000])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот он, красавец! Выброс налицо: гигантская жилая площадь (life_sq), да ещё почти в 100 раз превышает общую площадь (full_sq).\n",
    "\n",
    "Логичен вопрос: а много ли у нас таких квартир, у которых жилая площадь больше, чем суммарная?\n",
    "\n",
    "Давайте проверим это с помощью фильтрации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = sber_data[sber_data['life_sq'] > sber_data['full_sq']]\n",
    "print(outliers.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таких квартир оказывается 37 штук. Подобные наблюдения уже не поддаются здравому смыслу — они являются ошибочными, и от них стоит избавиться. Для этого можно воспользоваться методом drop() и удалить записи по их индексам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = sber_data.drop(outliers.index, axis=0)\n",
    "print(f'Результирующее число записей: {cleaned.shape[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё пример: давайте посмотрим на признак числа этажей (floor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sber_data['floor'].describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова видим подозрительную максимальную отметку в 77 этажей. Проверим все квартиры, которые находятся выше 50 этажей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sber_data[sber_data['floor']> 50])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего одна квартира в Ломоносовском районе. Пора идти в интернет в поиске самых высоких зданий в Москве! \n",
    "\n",
    "Убеждаемся в том, что здания выше 70 этажей находятся на территории комплекса Москва-Сити (Пресненский район). В Ломоносовском районе таких жилых высоток нет. Получается, что данное наблюдение — выброс."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод межквартильного размаха (метод Тьюки)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отличным помощником в поиске потенциальных выбросов является визуализация. Если признак является числовым, то можно построить гистограмму или коробчатую диаграмму, чтобы найти аномалии.\n",
    "\n",
    "На гистограмме мы можем увидеть потенциальные выбросы как низкие далеко отстоящие от основной группы столбцов «пеньки», а на коробчатой диаграмме — точки за пределами усов.\n",
    "\n",
    "Построим гистограмму и коробчатую диаграмму для признака полной площади (full_sq):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 4))\n",
    "histplot = sns.histplot(data=sber_data, x='full_sq', ax=axes[0]);\n",
    "histplot.set_title('Full Square Distribution');\n",
    "boxplot = sns.boxplot(data=sber_data, x='full_sq', ax=axes[1]);\n",
    "boxplot.set_title('Full Square Boxplot');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализация помогает определить наличие выбросов. Для того чтобы их найти, можно воспользоваться статистическими подходами. \n",
    "\n",
    "Одним из таких подходов является метод межквартильного размаха (его еще называют методом Тьюки), который используется для построения коробчатой диаграммы.\n",
    "\n",
    "Алгоритм метода:\n",
    "\n",
    "→ вычислить 25-ый и 75-ый квантили (первый и третий квартили) — и для признака, который мы исследуем;\n",
    "\n",
    "→ вычислить межквартильное расстояние:\n",
    "\n",
    "→ вычислить верхнюю и нижнюю границы Тьюки: \n",
    "\n",
    "→ найти наблюдения, которые выходят за пределы границ.\n",
    "\n",
    "В соответствии с этим алгоритмом напишем функцию outliers_iqr(), которая вам может ещё не раз пригодиться в реальных задачах. Эта функция принимает на вход DataFrame и признак, по которому ищутся выбросы, а затем возвращает потенциальные выбросы, найденные с помощью метода Тьюки, и очищенный от них датасет.\n",
    "\n",
    "Квантили вычисляются с помощью метода quantile(). Потенциальные выбросы определяются при помощи фильтрации данных по условию выхода за пределы верхней или нижней границы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_iqr(data, feature):\n",
    "    x = data[feature]\n",
    "    quartile_1, quartile_3 = x.quantile(0.25), x.quantile(0.75),\n",
    "    iqr = quartile_3 - quartile_1\n",
    "    lower_bound = quartile_1 - (iqr * 1.5)\n",
    "    upper_bound = quartile_3 + (iqr * 1.5)\n",
    "    outliers = data[(x < lower_bound) | (x > upper_bound)]\n",
    "    cleaned = data[(x >= lower_bound) & (x <= upper_bound)]\n",
    "    return outliers, cleaned"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим эту функцию к таблице sber_data и признаку full_sq, а также выведем размерности результатов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers, cleaned = outliers_iqr(sber_data, 'full_sq')\n",
    "print(f'Число выбросов по методу Тьюки: {outliers.shape[0]}')\n",
    "print(f'Результирующее число записей: {cleaned.shape[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Согласно классическому методу Тьюки, под выбросы у нас попали 963 записи в таблице. Давайте построим гистограмму и коробчатую диаграмму на новых данных cleaned_sber_data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 4))\n",
    "histplot = sns.histplot(data=cleaned, x='full_sq', ax=axes[0]);\n",
    "histplot.set_title('Cleaned Full Square Distribution');\n",
    "boxplot = sns.boxplot(data=cleaned, x='full_sq', ax=axes[1]);\n",
    "boxplot.set_title('Cleaned Full Square Boxplot');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На первый взгляд — стерильно. Однако если присмотреться, то коробчатая диаграмма всё ещё продолжает говорить, что в данных есть одиночные выбросы с обеих сторон от границ. К тому же у нас сильно урезался диапазон жилой площади — максимальная площадь составляет около 100 кв. м. \n",
    "\n",
    "Как же так, неужели метод не работает?\n",
    "\n",
    "Причина кроется в том, что после удаления выбросов квартили рассчитываются заново по новым данным, и так оказалось, что из-за свойств распределения были снова найдены точки, которые считаются выбросами.\n",
    "\n",
    "Классический метод межквартильного размаха не учитывает особенностей распределения! Он требует, чтобы данные были распределены плюс-минус нормально (гистограмма должна быть похожа на колокол) и требует от распределения примерной симметричности (чтобы у гистограммы были одинаковые хвосты в обе стороны).\n",
    "\n",
    "У нас же распределение (даже после отсечения выбросов) отличается от заявленных критериев. Оно несимметрично: правый хвост изначального распределения гораздо длиннее левого (для Москвы вполне естественны квартиры с площадью свыше 100 квадратных метров) и вовсе не колоколообразно. Попросту говоря, выбор метода поиска не оправдал себя.\n",
    "\n",
    "Но не стоит расстраиваться! Никто не говорил, что вы должны должны ограничиваться только 1.5 межквартильных размахов. Вы можете сами подбирать число размахов влево и/или вправо и таким образом отбирать выбросы, учитывая особенности ваших данных. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте немного модифицируем функцию outliers_iqr(). Добавьте в неё параметры left и right, которые задают число IQR влево и вправо от границ ящика (пусть по умолчанию они равны 1.5). Функция, как и раньше, должна возвращать потенциальные выбросы и очищенный DataFrame."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте немного модифицируем функцию outliers_iqr(data, feature). Добавьте в неё параметры left и right, которые задают число IQR влево и вправо от границ ящика (пусть по умолчанию они равны 1.5). Функция, как и раньше, должна возвращать потенциальные выбросы и очищенный DataFrame.\n",
    "\n",
    "Назовите измененную функцию: outliers_iqr_mod`\n",
    "\n",
    "Можете протестировать работу функции на DataFrame test_sber_data.csv. (На сайте Скиллфэктори)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_iqr(data, feature, left=1.5, right=1.5):\n",
    "    x = data[feature]\n",
    "    quartile_1, quartile_3 = x.quantile(0.25), x.quantile(0.75),\n",
    "    iqr = quartile_3 - quartile_1\n",
    "    lower_bound = quartile_1 - (iqr * left)\n",
    "    upper_bound = quartile_3 + (iqr * right)\n",
    "    outliers = data[(x < lower_bound) | (x > upper_bound)]\n",
    "    cleaned = data[(x >= lower_bound) & (x <= upper_bound)]\n",
    "    return outliers, cleaned"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте ослабим границы метода Тьюки справа и усилим их влево. Примените модифицированную функцию outliers_iqr_mod() к признаку full_sq из таблицы sber_data данным с параметрами left=1 и right=6. Результаты работы поместите в переменные outliers и cleaned. Чему равно результирующее число выбросов в данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers, cleaned = outliers_iqr(sber_data, 'full_sq', left=1, right=6)\n",
    "print(f'Число выбросов по методу Тьюки: {outliers.shape[0]}')\n",
    "print(f'Результирующее число записей: {cleaned.shape[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы построим гистограмму и коробчатую диаграмму на полученных данных, то увидим вот такую картинку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 4))\n",
    "histplot = sns.histplot(data=cleaned, x='full_sq', ax=axes[0]);\n",
    "histplot.set_title('Cleaned Full Square Distribution');\n",
    "boxplot = sns.boxplot(data=cleaned, x='full_sq', ax=axes[1]);\n",
    "boxplot.set_title('Cleaned Full Square Boxplot');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда для распределений, похожих на логнормальное, может помочь логарифмирование. Оно может привести исходное распределение к подобию нормального. Причем, основание логарифма может быть любым.\n",
    "\n",
    "Рассмотрим логарифмирование на примере. \n",
    "\n",
    "Построим две гистограммы признака расстояния до МКАД (mkad_km): первая — в обычном масштабе, а вторая — в логарифмическом. Логарифмировать будем с помощью функции log() из библиотеки numpy (натуральный логарифм — логарифм по основанию числа e). Признак имеет среди своих значений 0. Из математики известно, что логарифма от 0 не существует, поэтому мы прибавляем к нашему признаку 1, чтобы не логарифмировать нули и не получать предупреждения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 4))\n",
    "#гистограмма исходного признака\n",
    "histplot = sns.histplot(sber_data['mkad_km'], bins=30, ax=axes[0])\n",
    "histplot.set_title('MKAD Km Distribution');\n",
    "#гистограмма в логарифмическом масштабе\n",
    "log_mkad_km= np.log(sber_data['mkad_km'] + 1)\n",
    "histplot = sns.histplot(log_mkad_km , bins=30, ax=axes[1])\n",
    "histplot.set_title('Log MKAD Km Distribution');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Численный показатель асимметрии можно вычислить с помощью метода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_mkad_km.skew())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте реализуем алгоритм метода z-отклонения. Описание алгоритма метода:\n",
    "\n",
    "→ вычислить математическое ожидание (среднее) и стандартное отклонение признака ;\n",
    "\n",
    "→ вычислить нижнюю и верхнюю границу интервала как:\n",
    "\n",
    "→ найти наблюдения, которые выходят за пределы границ.\n",
    "\n",
    "Напишем функцию outliers_z_score(), которая реализует этот алгоритм. \n",
    "\n",
    "На вход она принимает DataFrame и признак, по которому ищутся выбросы. В дополнение добавим в функцию возможность работы в логарифмическом масштабе: для этого введём аргумент log_scale. Если он равен True, то будем логарифмировать рассматриваемый признак, иначе — оставляем его в исходном виде.\n",
    "\n",
    "Как и раньше, функция будет возвращать выбросы и очищенные от них данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_z_score(data, feature, log_scale=False):\n",
    "    if log_scale:\n",
    "        x = np.log(data[feature]+1)\n",
    "    else:\n",
    "        x = data[feature]\n",
    "    mu = x.mean()\n",
    "    sigma = x.std()\n",
    "    lower_bound = mu - 3 * sigma\n",
    "    upper_bound = mu + 3 * sigma\n",
    "    outliers = data[(x < lower_bound) | (x > upper_bound)]\n",
    "    cleaned = data[(x >= lower_bound) & (x <= upper_bound)]\n",
    "    return outliers, cleaned"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим эту функцию к таблице sber_data и признаку mkad_km, а также выведем размерности результатов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers, cleaned = outliers_z_score(sber_data, 'mkad_km', log_scale=True)\n",
    "print(f'Число выбросов по методу z-отклонения: {outliers.shape[0]}')\n",
    "print(f'Результирующее число записей: {cleaned.shape[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, метод z-отклонения нашел нам 33 потенциальных выброса по признаку расстояния до МКАД. Давайте узнаем, в каких районах (sub_area) представлены эти квартиры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outliers['sub_area'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наши потенциальные выбросы — это квартиры из поселений «Роговское» и «Киевский». Снова обращаемся к силе интернета и «пробиваем» наших подозреваемых. Эти поселения — самые удалённые районы Москвы; первое из них — это и вовсе граница с Калужской областью. \n",
    "\n",
    "И тут возникает закономерный вопрос: а стоит ли считать такие наблюдения за выбросы? \n",
    "\n",
    "Вопрос в действительности не имеет определенного ответа: с одной стороны, метод прямо-таки говорит нам об этом, а с другой — эти наблюдения имеют право на существование, ведь они являются частью Москвы."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно, мы не учли того факта, что наш логарифм распределения всё-таки не идеально нормален и в нём присутствует некоторая асимметрия. Возможно, стоит дать некоторое «послабление» на границы интервалов? Давайте отдельно построим гистограмму прологарифмированного распределения, а также отобразим на гистограмме вертикальные линии, соответствующие среднему (центру интервала в методе трёх сигм) и границы интервала . Вертикальные линии можно построить с помощью метода axvline(). Для среднего линия будет обычной, а для границ интервала — пунктирной (параметр ls ='--'): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "log_mkad_km = np.log(sber_data['mkad_km'] + 1)\n",
    "histplot = sns.histplot(log_mkad_km, bins=30, ax=ax)\n",
    "histplot.axvline(log_mkad_km.mean(), color='k', lw=2)\n",
    "histplot.axvline(log_mkad_km.mean()+ 3 * log_mkad_km.std(), color='k', ls='--', lw=2)\n",
    "histplot.axvline(log_mkad_km.mean()- 3 * log_mkad_km.std(), color='k', ls='--', lw=2)\n",
    "histplot.set_title('Log MKAD Km Distribution');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте расширим правило трёх сигм, чтобы иметь возможность особенности данных. Добавьте в функцию outliers_z_score() параметры left и right, которые будут задавать число сигм (стандартных отклонений) влево и вправо соответственно, определяющее границы метода z-отклонения. По умолчанию оба параметры равны 3. Результирующую функцию назовите outliers_z_score_mod()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_z_score_mod(data, feature, log_scale=False, left=3, right=3):\n",
    "    if log_scale:\n",
    "        x = np.log(data[feature]+1)\n",
    "    else:\n",
    "        x = data[feature]\n",
    "    mu = x.mean()\n",
    "    sigma = x.std()\n",
    "    lower_bound = mu - left * sigma\n",
    "    upper_bound = mu + right * sigma\n",
    "    outliers = data[(x < lower_bound) | (x > upper_bound)]\n",
    "    cleaned = data[(x >= lower_bound) & (x <= upper_bound)]\n",
    "    return outliers, cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers, cleaned = outliers_z_score_mod(sber_data, 'mkad_km', log_scale=True, left=3, right=3.5)\n",
    "print(f'Число выбросов по методу z-отклонения: {outliers.shape[0]}')\n",
    "print(f'Результирующее число записей: {cleaned.shape[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работа с дубликатами и енинформативными признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sber_data['id'].nunique() == sber_data.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдём число полных дубликатов таблице sber_data. Предварительно создадим список столбцов dupl_columns, по которым будем искать совпадения (все столбцы, не включая id). \n",
    "\n",
    "Создадим маску дубликатов с помощью метода duplicated() и произведём фильтрацию. Результат заносим в переменную sber_duplicates. Выведем число строк в результирующем DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число найденных дубликатов: 562\n"
     ]
    }
   ],
   "source": [
    "dupl_columns = list(sber_data.columns)\n",
    "dupl_columns.remove('id')\n",
    "\n",
    "mask = sber_data.duplicated(subset=dupl_columns)\n",
    "sber_duplicates = sber_data[mask]\n",
    "print(f'Число найденных дубликатов: {sber_duplicates.shape[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, 562 строки в таблице являются полными копиями других записей. Ручной поиск совпадающих строк по 30 тысячам записей был бы практически невыполним, а с помощью pandas мы быстро, а главное, легко обнаружили дублирующиеся данные!\n",
    "\n",
    "Теперь нам необходимо от них избавиться. Для этого легче всего воспользоваться методом drop_duplicates(), который удаляет повторяющиеся записи из таблицы. \n",
    "\n",
    "Создадим новую таблицу sber_dedupped, которая будет версией исходной таблицы, очищенной от полных дубликатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результирующее число записей: 29909\n"
     ]
    }
   ],
   "source": [
    "sber_dedupped = sber_data.drop_duplicates(subset=dupl_columns)\n",
    "print(f'Результирующее число записей: {sber_dedupped.shape[0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
